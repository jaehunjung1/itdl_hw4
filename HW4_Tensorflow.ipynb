{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 Introduction to Deep Learning HW4: Fake News Generator!\n",
    "\n",
    "Created by Yeon-goon Kim, SNU ECE, CML.\n",
    "\n",
    "On this homework, you will create fake news generator, which is basic RNN/LSTM/GRU char2char generate model. Of course, your results may not so good, but you can expect some sentence-like results by doing this homework sucessfully.\n",
    "\n",
    "## Now, We'll handle texts, not images. Is there any differences?\n",
    "\n",
    "Of course, there are many differences between processing images and texts. One is that text cannot be expressed directly to matrix or tensor. We know an image can be expressed as Tensor(n_channel, width, height). But how about text? Can word 'Homework' can be expressed to tensor directly? By what laws? With what shapes? Even if it can, which one is closer to that word, 'Burden', or 'Work'? This is called 'Word Embedding Problem' and be considered as one of the most important problem in Natural Language Process(NLP) resarch. Fortunatly, there are some generalized solution in this problem (though not prefect, anyway) and both Tensorflow(Keras) and Pytorch give basic API that automatically solve this problem. You may investigate and use those APIs in this homework. \n",
    "\n",
    "The other one is that text is sequential data. Generally when processing images, without batch, input is just one image. However in text, input is mostly some or one paragraphs/sentences, which is sequential data of embedded characters or words. So, If we want to generate word 'Homework' with start token 'H', 'o' before 'H' and 'o' before 'Homew' should operate different when it gives to input. This is why we use RNN-based model in deep learning when processing text data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement\n",
    "In this homework file, you should use the latest version of Tensorflow_r1, which is on now(2019-11-19) Tensorflow 1.15.x.. Maybe you should use python3.7 because python3.8 may not compatible and inconsistent now. And to use dataset, you must install 'pandas' package, which that give convinience to read and manipulate .csv files. You can easilly install the package with command 'pip install pandas' or with conda if you use conda venv. Don't be so worry that you don't need to know how to use it, data pre-process code will be given. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages & Create Dataset\n",
    "These codes will create dataset that automatically change each character in texts to int, which is assigned index by vocab.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/jay/anaconda3/envs/dlstudy/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/Users/jay/anaconda3/envs/dlstudy/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/Users/jay/anaconda3/envs/dlstudy/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/Users/jay/anaconda3/envs/dlstudy/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/Users/jay/anaconda3/envs/dlstudy/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/Users/jay/anaconda3/envs/dlstudy/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jay/anaconda3/envs/dlstudy/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/Users/jay/anaconda3/envs/dlstudy/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/Users/jay/anaconda3/envs/dlstudy/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/Users/jay/anaconda3/envs/dlstudy/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/Users/jay/anaconda3/envs/dlstudy/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/Users/jay/anaconda3/envs/dlstudy/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "using device: /cpu:0\n",
      "WARNING:tensorflow:From /Users/jay/anaconda3/envs/dlstudy/lib/python3.7/site-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From <ipython-input-1-d8b14cbb88be>:45: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.data.get_output_shapes(dataset)`.\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "(TensorShape([Dimension(64), Dimension(64)]),\n TensorShape([Dimension(64), Dimension(64)]))"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "####### This Code should not be changed except 'USE_GPU'. Please mail to T/A if you must need to change with proper description.\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "########### Change whether you would use GPU on this homework or not ############\n",
    "USE_GPU = False\n",
    "#################################################################################\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "print('using device:', device)\n",
    "\n",
    "vocab = open('vocab.txt').read().splitlines()\n",
    "n_vocab = len(vocab)\n",
    "tf.random.set_random_seed(1)\n",
    "\n",
    "# Change char to index.\n",
    "def text2idx(csv_file, dname, vocab):\n",
    "    ret = []\n",
    "    data = csv_file[dname].values\n",
    "    for datum in data:\n",
    "        for char in str(datum):\n",
    "            idx = vocab.index(char)\n",
    "            ret.append(idx)\n",
    "    ret = np.array(ret)\n",
    "    return ret\n",
    "\n",
    "\n",
    "# Create dataset to automatically iterate.\n",
    "csv_file = pd.read_csv('data.csv', sep='|')\n",
    "\n",
    "with tf.device(device):\n",
    "    x = text2idx(csv_file, 'x_data', vocab)\n",
    "    y = text2idx(csv_file, 'y_data', vocab)\n",
    "    \n",
    "seq_length = 64\n",
    "examples_per_epoch = len(x)//seq_length\n",
    "batch_size = 64\n",
    "steps_per_epoch = examples_per_epoch//batch_size\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x,y)).shuffle(10000).repeat().batch(64, drop_remainder=True).batch(64, drop_remainder=True)\n",
    "dataset.output_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1: RNN/LSTM/GRU Module\n",
    "\n",
    "The main task is to create RNN/LSTM/GRU network that both input & output shape is (batch_size, vocab_size). You can use Tensorflow/Keras api such as tf.keras.Model, tf.keras.Sequential or barebone tensorflow such as tf.layer.XXX. You can use any of tensorflow api that basically given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### WRITE DOWN YOUR CODE ################################\n",
    "## Task_recommended form. You can use another form but in that case you may need to change some test or train code that given on later.\n",
    "def selfModule(### args you need):\n",
    "    return model\n",
    "#################### WRITE DOWN YOUR CODE ################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Task: Test Code\n",
    "\n",
    "This code would define test function that test network by generating (max_length)-length character sequence from 'start_letter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Test Code. On mostly you don't need to change this except value of 'max_length', but ok if you really need to do it.\n",
    "def test(model, start_letter, n_vocab):\n",
    "    max_length = 1000\n",
    "    idx = vocab.index(start_letter)\n",
    "    input_t = tf.constant([[idx]])\n",
    "    output_sen = start_letter\n",
    "    model.reset_states()\n",
    "    for i in range(max_length):\n",
    "        predictions = model(input_t)\n",
    "        predictions = tf.squeeze(predictions)\n",
    "        idx = tf.math.argmax(predictions)\n",
    "        output_sen += vocab[idx.numpy()]        \n",
    "        input_t = tf.constant([[idx.numpy()]])\n",
    "    return output_sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2: Train & Generate\n",
    "\n",
    "Using above defined functions and network, Do your train process and show your results freely! Since this is generating tasks so there are no clear test set, credits are given based on quality of generated sequence. Please see the document to find criterion. (Hint: See your loss carefully, and if final loss is between 1~2 or more, you will get results that match to basic credit. If final loss is under ~0.1, you will get results that match to full credit.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## main Code. You can chage code on this cell or hyperparameter freely. \n",
    "do_restore = False\n",
    "\n",
    "model = selfModule(20, n_vocab, 128, batch_size)\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer = tf.train.AdamOptimizer(learning_rate=0.01,\n",
    "                                                 beta1=0.9,\n",
    "                                                 beta2=0.999,\n",
    "                                                 epsilon=2e-16),\n",
    "              loss = loss)\n",
    "\n",
    "if do_restore:\n",
    "    model.load_weights('fng_tf.h5')\n",
    "\n",
    "else:\n",
    "    model.fit(dataset, epochs=10, steps_per_epoch=steps_per_epoch)\n",
    "    model.save_weights('fng_tf.h5')\n",
    "\n",
    "old_weights = model.get_weights()\n",
    "t_model = selfModule(20, n_vocab, 128, 1)\n",
    "t_model.set_weights(old_weights)\n",
    "print(test(t_model, 'W', n_vocab))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}